{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "outputs": [],
      "source": [
        "<a href=\"https://colab.research.google.com/github/ErikSeguinte/movie_data/blob/master/processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cufflinks as cf\n",
        "import numpy as np\n",
        "from plotly import graph_objs as go\n",
        "import altair as alt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merge_keys = {'left_index':True, 'right_index':True}"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "cHmXX2xrlfbZ"
      },
      "outputs": [],
      "source": [
        "* I previously pulled CSV files from Kaggle, but the files were too big to host on github.\n",
        "* I imported the files I wanted into pandas, and then exported them back out as compressed pickles.\n",
        "* I was able to compress a 700MB csv to a 3 MB Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try: \n",
        "    movies = pd.read_pickle('data/movies.pkl.xz')\n",
        "    ratings = pd.read_pickle('data/ratings2.pkl.xz')\n",
        "    cpi = pd.read_csv('data/cpi.csv')\n",
        "    \n",
        "except:\n",
        "    # Download pickles from github\n",
        "    cpi = pd.read_csv('https://datahub.io/core/cpi/r/cpi.csv')\n",
        "    movies = pd.read_pickle('https://github.com/ErikSeguinte/movie_data/raw/master/data/movies.pkl.xz')\n",
        "    ratings = pd.read_pickle('https://github.com/ErikSeguinte/movie_data/raw/master/data/ratings2.pkl.xz')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "HiXoKaRQqYr9"
      },
      "outputs": [],
      "source": [
        "## Clean Movie DF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Y8o7MEkpmX3Z"
      },
      "outputs": [],
      "source": [
        "* Movies Dataframe has malformed data. `id` Should be numeric.\n",
        "* After inspection, it looks like there are rows that are missing a comma somewhere, making columns not line up, and adding the wrong data to columns. Let's clean those up.\n",
        "* All malformed rows have strings for IDs instead of numeric, so we will coerce them into numeric columns, and strings will be returned as `NaN`, which we'll then drop.\n",
        "\n",
        "* `budget` and `revanue` should also be numeric, but Nans won't be dropped\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies['id'] = pd.to_numeric(movies['id'], errors='coerce')\n",
        "movies = movies[movies['id'].notnull()]\n",
        "movies = movies.set_index('id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def to_numeric(df, labels):\n",
        "    \n",
        "    for label in labels:\n",
        "        df[label] = pd.to_numeric(movies[label], errors='coerce').copy()\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies = to_numeric(movies, ['budget', 'revenue', 'vote_average'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies['release_date'] =pd.to_datetime(movies['release_date'], infer_datetime_format= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movies['year'] = movies['release_date'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies = movies[['title','genres', 'release_date','budget', 'revenue','year' ,'runtime', 'vote_average', 'vote_count']]"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "iW-7lxUXqdJL"
      },
      "outputs": [],
      "source": [
        "## Process User Reviews\n",
        "* User reviews come in a collection of individual reviews where a review gives a movie a score of 1 to 5.\n",
        "* We will take the mean ratings for each movie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate mean ratings and number of votes per movie\n",
        "movie_ratings =pd.DataFrame(ratings.groupby('movieId')[['rating']].agg(['mean', 'count']))['rating']\n",
        "movie_ratings = movie_ratings.rename({'mean': 'rating', 'count': 'num_votes'}, axis = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "NScOxazLtC9g"
      },
      "outputs": [],
      "source": [
        "* Lets drop any movies with less than 100 votes. Those are more easily swayed by outliers and aren't reliable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "movie_ratings = movie_ratings[(movie_ratings['num_votes'] >= 100)]"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "Ht36bnK3q0ra"
      },
      "outputs": [],
      "source": [
        "* And now we merge the averaged ratings back with the movie database.\n",
        "* Note that not all movies are present in the user votings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies = clean_movies.merge(movie_ratings, left_index = True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies[['title', 'rating', 'num_votes']].nlargest(10, 'rating')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "N1eWDvY9tC9x"
      },
      "outputs": [],
      "source": [
        "* The movie Database also provides a rating and suffer from a similar problem of some movies having a tiny sample size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies[clean_movies['vote_count'] >= 100][['title', 'vote_average', 'vote_count']].nlargest(10, 'vote_average')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies[['title', 'revenue']].nlargest(10, 'revenue')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "r-9nL1-6tC97"
      },
      "outputs": [],
      "source": [
        "## Inflation\n",
        "* Inflation means that a 1940 dollar is worth more than a 2020 dollar. Let's adjust Revenue for that.\n",
        "* The Consumer price index can be used to convert to standarized dollars.\n",
        "* Here, we'll be using 2014 dollars.\n",
        "* Years later than 2014 will not be adjusted.\n",
        "$$ \\textrm{adjusted dollars} = \\frac{\\textrm{New CPI}}{\\textrm{Base CPI}}$$\n",
        "* where x is the current cpi and y is the cpi of that year "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cpi = cpi[cpi['Country Name'] == 'United States'][['Year', 'CPI']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cpi = cpi.set_index(cpi['Year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def adjust_dollars(value, year):\n",
        "    year = int(year)\n",
        "    try:\n",
        "        current = cpi.loc[2014,'CPI']\n",
        "        base = cpi.loc[year,'CPI']\n",
        "        adjusted_value = value * (current/base)\n",
        "        return adjusted_value\n",
        "    except: \n",
        "        return value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies['year']= clean_movies['release_date'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = clean_movies[clean_movies['revenue'].notnull() & clean_movies['year'].notnull()]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "adjusted = pd.DataFrame([adjust_dollars(x,y) for x,y in zip(df['revenue'], df['year'])], index = df.index, columns = ['adjusted_revenue'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies = clean_movies.merge(adjusted, left_index=True, right_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies[['title', 'adjusted_revenue']].nlargest(10, 'adjusted_revenue')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies['decade'] = [x - (x%10) for x in clean_movies['year']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#enable_plotly_in_cell()\n",
        "clean_movies.groupby('year')['vote_average'].mean().iplot(kind='bar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alt.data_transformers.disable_max_rows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alt.Chart(clean_movies, width=1080).mark_bar().encode(\n",
        "    alt.Y('mean(vote_average)'),\n",
        "    alt.X('year(release_date):O')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alt.Chart(clean_movies, width=1080).mark_bar().encode(\n",
        "    alt.Y('mean(rating)'),\n",
        "    alt.X('year(release_date):N')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alt.Chart(clean_movies,width=720).mark_bar().encode(\n",
        "    alt.Y('mean(vote_average)'),\n",
        "    alt.X('decade:O')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "pz4qcRPrtC-6"
      },
      "outputs": [],
      "source": [
        "* I'd like to compare the votes from TMB to the user ratings, but they are on different scales. We'll use standard scaler to normalize them so we can more easily compare."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "to_scale = clean_movies[['vote_average', 'rating']].dropna()\n",
        "scaled = scaler.fit_transform(to_scale)\n",
        "clean_movies = clean_movies.merge(\n",
        "    pd.DataFrame(\n",
        "        scaled,\n",
        "        index = to_scale.index,\n",
        "        columns = ['scaled_tmdb_vote', 'scaled_user_rating']\n",
        "    ),\n",
        "    left_index = True,\n",
        "    right_index = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "traces = [\n",
        "    go.Bar(name='TMDB rating',\n",
        "        x = clean_movies.groupby('decade')['scaled_tmdb_vote'].mean().index,\n",
        "        y = clean_movies.groupby('decade')['scaled_tmdb_vote'].mean()\n",
        "    ),\n",
        "        go.Bar(name='user rating',\n",
        "        x = clean_movies.groupby('decade')['scaled_user_rating'].mean().index,\n",
        "        y = clean_movies.groupby('decade')['scaled_user_rating'].mean()\n",
        "    )\n",
        "]\n",
        "\n",
        "go.Figure(data = traces,\n",
        "    layout_xaxis_tick0 = 1890\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(1)\n",
        "\n",
        "to_scale = clean_movies[['vote_average', 'rating', 'adjusted_revenue']].dropna()\n",
        "scaled = scaler.fit_transform(to_scale)\n",
        "\n",
        "pca_df = pd.DataFrame(pca.fit_transform(scaled), index=to_scale.index, columns = ['PCA'])\n",
        "\n",
        "clean_movies = clean_movies.merge(pca_df, left_index = True, right_index = True)\n",
        "clean_movies.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies[['title', 'PCA']].nlargest(25, 'PCA')"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "|      | title                                         |     PCA |\n",
        "|-----:|:----------------------------------------------|--------:|\n",
        "|   11 | Star Wars                                     | 8.86514 |\n",
        "|  597 | Titanic                                       | 7.50724 |\n",
        "|  601 | E.T. the Extra-Terrestrial                    | 5.27108 |\n",
        "| 1891 | The Empire Strikes Back                       | 4.81926 |\n",
        "|  238 | The Godfather                                 | 4.75741 |\n",
        "|  122 | The Lord of the Rings: The Return of the King | 4.51399 |\n",
        "|  329 | Jurassic Park                                 | 4.3515  |\n",
        "| 1892 | Return of the Jedi                            | 4.21927 |\n",
        "|  121 | The Lord of the Rings: The Two Towers         | 3.98178 |\n",
        "|  155 | The Dark Knight                               | 3.87451 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_movies['q_budget'] = pd.qcut(clean_movies['budget'], labels = ['vlow', 'low', 'med', 'high', 'vhigh'], q = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "budget_ratings = clean_movies[['title','q_budget', 'budget', 'revenue', 'rating', 'vote_average']].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "alt.Chart(budget_ratings, width=720).mark_bar().encode(\n",
        "    x='q_budget:N',\n",
        "    y='mean(vote_average)'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trace = go.Scatter(\n",
        "    y = budget_ratings['vote_average'],\n",
        "    x = budget_ratings['revenue'],\n",
        "    mode = 'markers'\n",
        ")\n",
        "\n",
        "go.Figure(\n",
        "    trace,\n",
        "    layout_xaxis_title = \"Budget\",\n",
        "    layout_yaxis_title = \"Movie Rating\",\n",
        "    layout_title = \"Movie Ratings by budget\",\n",
        "    \n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "rIGUfYG9tDAi"
      },
      "outputs": [],
      "source": [
        "## Genre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "genres = clean_movies[['title','genres']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bad_genres = [\n",
        "           'Aniplex',\n",
        " 'BROSTA TV',\n",
        " 'Carousel Productions',   \n",
        "  'GoHands',\n",
        "   'Mardock Scramble Production Committee',\n",
        "    'Odyssey Media',\n",
        "     'Pulser Productions',\n",
        " 'Rogue State',\n",
        "  'Sentai Filmworks',\n",
        "   'Telescene Film Group Productions',\n",
        " 'The Cartel',\n",
        "  'Vision View Entertainment',\n",
        "]\n",
        "\n",
        "#genre_set = genre_set.difference(bad_genres)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "genres['genres_ls'] = [\n",
        "                    [d['name'] for d in ast.literal_eval(x) if d['name'] not in bad_genres ]\n",
        "                    for x in genres['genres']\n",
        "                    ]\n",
        "genres['genres_ls']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlb = MultiLabelBinarizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlb_ = mlb.fit_transform(genres['genres_ls'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_genres = pd.DataFrame(mlb_, columns = mlb.classes_, index = genres.index)\n",
        "encoded_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoded_genres = clean_movies.merge(encoded_genres, **merge_keys)\n",
        "encoded_genres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for genre in mlb.classes_:\n",
        "    print(genre, encoded_genres[encoded_genres[genre] == 1]['vote_average'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d = {g: [encoded_genres[encoded_genres[g] == 1]['PCA'].mean(),\n",
        "         encoded_genres[encoded_genres[g] == 1]['adjusted_revenue'].sum()]\n",
        "     for g in mlb.classes_}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.DataFrame.from_dict(d, orient='index',  columns = ['pca rating', 'total revenue'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trace = go.Bar(\n",
        "    x=df.index,\n",
        "    y=df['pca rating']\n",
        ")\n",
        "\n",
        "go.Figure(\n",
        "    data = trace,\n",
        "    #layout_x)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "melted = df.reset_index().melt(id_vars='index')\n",
        "melted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}